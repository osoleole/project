{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lamedoc. Model testing and eavluation\n",
    "\n",
    "To be really useful, any machine-learning algorithms and models must be tested and evaluated. \n",
    "That is mandatory, and there is no exception.\n",
    "Nobody wants to get unexpected results from the algorithm in production, even if its main objective is just to find kitties' photos.\n",
    "\n",
    "## Model elaboration workflow\n",
    "\n",
    "At the first stage of working on the problem we define the model and state the hypothesis that this model is the best solution for our task. After that, we construct the algorithm that implements our model and start our evaluation workflow. \n",
    "Workflow consists of three continiously repeating stages:\n",
    "1. traning\n",
    "2. developing\n",
    "3. testing\n",
    "\n",
    "This workflow repeats untill we get the results that satisfy us. At the third stage we evaluate the performanse of our model, test it on the tresppasing of all restriction, and deside whether to continue our stages or stop the training process and move out to the production.\n",
    "\n",
    "To successfully evaluate model we have to define the main parameters and restriction we impose on it.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "For any model we are going to train, tune, evaluate and test, first of all we need data. We need three datasets to be used: training data, development data, test data. Training data should have distribution other than development data and test data.\n",
    "Now more about dataset.\n",
    "\n",
    "### Training data\n",
    "\n",
    "Training data is the main source of the information our algorithm uses to retrieve the data's underlying structure and knowledge. It is used by the algorithm to fit the weights parameters of our model in such a way that it could predict output from the input. The more data we use for the training the better.  \n",
    "\n",
    "### Development data\n",
    "\n",
    "Development data is used at the stage of experiments when you need to tweak some parameters of algorithm to improve its performance.  \n",
    "\n",
    "### Testing data \n",
    "\n",
    "Testing data is used to assure that model behaves as we expected.\n",
    "\n",
    "### Data subdivision\n",
    "\n",
    "There are many euristics how to subdivide the initial dataset to the three aforemntioned categories. It strongly depends on the type of data, type of the algorithm and result we are striving to get. Usually intial dataset is subdivided as follows:\n",
    "1. training data - 70%\n",
    "2. development data - 20%\n",
    "3. test data - 10%\n",
    "\n",
    "In our case, we are using two initial datasets: one is domain-specific texts, second is syntetic requests datatset.\n",
    "The first one we use exceptionally to train the model.\n",
    "The second one we subdivide to the development and the test sets as 50%/50%\n",
    "\n",
    "## Performance evaluation\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:lamedoc]",
   "language": "python",
   "name": "conda-env-lamedoc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
