{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed vector representation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trigram sentence\n",
    "trigram_sentences = LineSentence(os.path.join(settings.DATA_PATH,'trigram_sentences.txt'))\n",
    "# Path where model will be saved\n",
    "word2vec_filepath = os.path.join(settings.DATA_PATH, 'word2vec_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start word2vec model training. Set vector dimension and epochs number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run it to retrain our model. Model will be saved in \"word2vec_filepath\"\n",
    "# Most important training parameters:\n",
    "# size - word vector dimension\n",
    "# window - context size\n",
    "\n",
    "# Training parameters\n",
    "# Word vector dimension \n",
    "vector_dim = 100\n",
    "# Context size\n",
    "context_size = 5\n",
    "# Training epochs\n",
    "epochs = 20\n",
    "\n",
    "# Make False to use pretraind models\n",
    "if True:\n",
    "    # Take trigram text and start first epoch\n",
    "    text2vec = Word2Vec(trigram_sentences, size=vector_dim, window=context_size,\n",
    "                        min_count=20, sg=1, workers=4)\n",
    "    # Save first iteration \n",
    "    text2vec.save(word2vec_filepath)\n",
    "    # Train another epochs and save model in \"word2vec_filepath\"\n",
    "    for i in range(1,epochs):\n",
    "        text2vec.train(trigram_sentences)\n",
    "        text2vec.save(word2vec_filepath)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load vector representation from trained 'word2vec_model'\n",
    "text2vec = Word2Vec.load(word2vec_filepath)\n",
    "text2vec.init_sims()\n",
    "\n",
    "# Shows number of training epochs\n",
    "print('{} training epochs.'.format(food2vec.train_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text word2vector to panda's data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of word2vector tuples\n",
    "ordered_vocab = [(term, voc.index, voc.count)\n",
    "                 for term, voc in text2vec.vocab.items()]\n",
    "\n",
    "# Sort oredred vocab by voc.count\n",
    "ordered_vocab = sorted(ordered_vocab, key=lambda count: count[2]) # try to use -count[2]\n",
    "\n",
    "# Make three lists of: terms, indices, counts\n",
    "ordered_terms, term_indices, term_counts = zip(*ordered_vocab)\n",
    "\n",
    "# Create panda's data frame of word vector representation\n",
    "word_vectors = pd.DataFrame(text2vec.syn0norm[term_indices, :],\n",
    "                            index=ordered_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get similar/realated word in context\n",
    "def get_context_related_words(token, topn=10):\n",
    "    '''Returns topn context related words as a dictionary'''\n",
    "    word_sim = {}\n",
    "    for word, similarity in text2vec.most_similar(positive=[token], topn=topn):\n",
    "        word_sim.update({word:similarity})\n",
    "    return word_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words meanings linear algebra function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_algebra(add=[], subtract=[], topn=1):\n",
    "    '''Returns topn words as the result of operations \n",
    "    add=['token1','token2']\n",
    "    subtract=['token1','token2']\n",
    "    '''\n",
    "    answers = text2vec.most_similar(positive=add, negative=subtract, topn=topn)\n",
    "    for term, similarity in answers:\n",
    "        print(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Distributed stochastic neighbor embedding\n",
    "Map high dimensional data to low dimensions 2 or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of vectors to apply t-SNE \n",
    "tsne_vectors = 600\n",
    "\n",
    "# Take data from panda's data frame. Remove stopwords from it.\n",
    "tsne_input = word_vectors.drop(spacy.en.STOPWORDS, errors=u'ignore')\n",
    "\n",
    "# Take the vectors  \n",
    "tsne_input = tsne_input.head(tsne_vectors)\n",
    "\n",
    "# Path to save model in binary file 'tsne_model'\n",
    "tsne_filepath = os.path.join(settings.DATA_PATH, 'tsne_model')\n",
    "\n",
    "# Path to save vectors in binary file 'tsne_model'\n",
    "tsne_vectors_filepath = os.path.join(settings.DATA_PATH, 'tsne_vectors.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains t-SNE dimension reduction. !!!Check additional twicks.\n",
    "# Saves t-sne model in file 'tsne_filepath'\n",
    "# Saves t-sne vectors in file 'tsne_vectors_filepath'\n",
    "if True:\n",
    "    tsne = TSNE()\n",
    "    tsne_vectors = tsne.fit_transform(tsne_input.values)\n",
    "    with open(tsne_filepath, 'wb') as f:\n",
    "        pickle.dump(tsne, f)\n",
    "    pd.np.save(tsne_vectors_filepath, tsne_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained t-SNE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loads t-SNE models\n",
    "with open(tsne_filepath, 'rb') as f:\n",
    "    tsne = pickle.load(f)\n",
    "\n",
    "# Loads t-SNE vectors from 'tsne_vectors_filepath'\n",
    "tsne_vectors = pd.np.load(tsne_vectors_filepath)\n",
    "\n",
    "# Converts tsne_vectors to panda's data frame\n",
    "tsne_vectors = pd.DataFrame(tsne_vectors,\n",
    "                            index=pd.Index(tsne_input.index),\n",
    "                            columns=[u'x_coord', u'y_coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>work_capital</th>\n",
       "      <td>2.273404</td>\n",
       "      <td>10.040244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_most_case</th>\n",
       "      <td>14.516599</td>\n",
       "      <td>4.917390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socalled</th>\n",
       "      <td>9.111805</td>\n",
       "      <td>4.795907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component</th>\n",
       "      <td>23.652160</td>\n",
       "      <td>3.793310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scope</th>\n",
       "      <td>-24.871328</td>\n",
       "      <td>-5.657409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x_coord    y_coord\n",
       "work_capital   2.273404  10.040244\n",
       "in_most_case  14.516599   4.917390\n",
       "socalled       9.111805   4.795907\n",
       "component     23.652160   3.793310\n",
       "scope        -24.871328  -5.657409"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just shows everyting is OK.\n",
    "tsne_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just renames field of panda's data frame \n",
    "tsne_vectors['word'] = tsne_vectors.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot t-SNE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, value\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add tsne_vectors from DataFrame to bokeh as ColumnDataSource \n",
    "plot_data = ColumnDataSource(tsne_vectors)\n",
    "\n",
    "# Create plot\n",
    "tsne_plot = figure(title='Word embeddings for M&A domain vector space',\n",
    "                   plot_width = 800,\n",
    "                   plot_height = 800,\n",
    "                   tools= ('pan, wheel_zoom, box_zoom,'\n",
    "                           'box_select, resize, reset'),\n",
    "                   active_scroll='wheel_zoom')\n",
    "\n",
    "# Add hover tool to plot\n",
    "tsne_plot.add_tools(HoverTool(tooltips = '@word'))\n",
    "\n",
    "# Plot words as circle\n",
    "tsne_plot.circle('x_coord', 'y_coord', source=plot_data,\n",
    "                 color='blue', line_alpha=0.2, fill_alpha=0.1,\n",
    "                 size=10, hover_line_color='black')\n",
    "# Title\n",
    "tsne_plot.title.text_font_size = value('16pt')\n",
    "\n",
    "# Axis parameters\n",
    "tsne_plot.xaxis.visible = False\n",
    "tsne_plot.yaxis.visible = False\n",
    "tsne_plot.grid.grid_line_color = None\n",
    "tsne_plot.outline_line_color = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:lamedoc]",
   "language": "python",
   "name": "conda-env-lamedoc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
